{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DateConvert.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtHL0VOrC/O8Dr8HtKYccI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suvam94/ML-trained-models/blob/gh-pages/StockPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg5_iF9MtaqJ",
        "outputId": "75e23ae4-28c7-48b4-fd2b-3d7fb098be92"
      },
      "source": [
        "pip install ta"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ta) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ta) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ta) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TzAau3MtCOK"
      },
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "plt.style.use(\"bmh\")\n",
        "import ta\n",
        "\n",
        "# Neural Network library\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Loading in the Data\n",
        "df = pd.read_csv(\"/content/sample_data/IDEA.NS.csv\")"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aJD0754tETe",
        "outputId": "f33a63bc-73f0-4ecf-ba7e-8d0d951f194a"
      },
      "source": [
        "## Datetime conversion\n",
        "df['Date'] = pd.to_datetime(df.Date)\n",
        "\n",
        "# Setting the index\n",
        "df.set_index('Date', inplace=True)\n",
        "\n",
        "# Dropping any NaNs\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "## Technical Indicators\n",
        "\n",
        "# Adding all the indicators\n",
        "df = ta.add_all_ta_features(df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\", fillna=True)\n",
        "\n",
        "# Dropping everything else besides 'Close' and the Indicators\n",
        "df.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1, inplace=True)\n",
        "\n",
        "# Only using the last 1000 days of data to get a more accurate representation of the current market climate\n",
        "#df = df.tail(10000)\n",
        "\n",
        "\n",
        "\n",
        "## Scaling\n",
        "\n",
        "# Scale fitting the close prices separately for inverse_transformations purposes later\n",
        "close_scaler = RobustScaler()\n",
        "\n",
        "close_scaler.fit(df[['Close']])\n",
        "\n",
        "# Normalizing/Scaling the DF\n",
        "scaler = RobustScaler()\n",
        "\n",
        "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dip[i] = 100 * (self._dip[i] / self._trs[i])\n",
            "/usr/local/lib/python3.7/dist-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  din[i] = 100 * (self._din[i] / self._trs[i])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpTSu-EgtPs5"
      },
      "source": [
        "def split_sequence(seq, n_steps_in, n_steps_out):\n",
        "    \"\"\"\n",
        "    Splits the multivariate time sequence\n",
        "    \"\"\"\n",
        "    \n",
        "    # Creating a list for both variables\n",
        "    X, y = [], []\n",
        "    \n",
        "    for i in range(len(seq)):\n",
        "        \n",
        "        # Finding the end of the current sequence\n",
        "        end = i + n_steps_in\n",
        "        out_end = end + n_steps_out\n",
        "        \n",
        "        # Breaking out of the loop if we have exceeded the dataset's length\n",
        "        if out_end > len(seq):\n",
        "            break\n",
        "        \n",
        "        # Splitting the sequences into: x = past prices and indicators, y = prices ahead\n",
        "        seq_x, seq_y = seq[i:end, :], seq[end:out_end, 0]\n",
        "        \n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    \n",
        "    return np.array(X), np.array(y)\n",
        "  \n",
        "  \n",
        "def visualize_training_results(results):\n",
        "    \"\"\"\n",
        "    Plots the loss and accuracy for the training and testing data\n",
        "    \"\"\"\n",
        "    history = results.history\n",
        "    plt.figure(figsize=(16,5))\n",
        "    plt.plot(history['val_loss'])\n",
        "    plt.plot(history['loss'])\n",
        "    plt.legend(['val_loss', 'loss'])\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(figsize=(16,5))\n",
        "    plt.plot(history['val_accuracy'])\n",
        "    plt.plot(history['accuracy'])\n",
        "    plt.legend(['val_accuracy', 'accuracy'])\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "def layer_maker(n_layers, n_nodes, activation, drop=None, d_rate=.5):\n",
        "    \"\"\"\n",
        "    Creates a specified number of hidden layers for an RNN\n",
        "    Optional: Adds regularization option - the dropout layer to prevent potential overfitting (if necessary)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Creating the specified number of hidden layers with the specified number of nodes\n",
        "    for x in range(1,n_layers+1):\n",
        "        model.add(LSTM(n_nodes, activation=activation, return_sequences=True))\n",
        "\n",
        "        # Adds a Dropout layer after every Nth hidden layer (the 'drop' variable)\n",
        "        try:\n",
        "            if x % drop == 0:\n",
        "                model.add(Dropout(d_rate))\n",
        "        except:\n",
        "            pass\n",
        "          \n",
        "          \n",
        "def validater(n_per_in, n_per_out):\n",
        "    \"\"\"\n",
        "    Runs a 'For' loop to iterate through the length of the DF and create predicted values for every stated interval\n",
        "    Returns a DF containing the predicted values for the model with the corresponding index values based on a business day frequency\n",
        "    \"\"\"\n",
        "    \n",
        "    # Creating an empty DF to store the predictions\n",
        "    predictions = pd.DataFrame(index=df.index, columns=[df.columns[0]])\n",
        "\n",
        "    for i in range(n_per_in, len(df)-n_per_in, n_per_out):\n",
        "        # Creating rolling intervals to predict off of\n",
        "        x = df[-i - n_per_in:-i]\n",
        "\n",
        "        # Predicting using rolling intervals\n",
        "        yhat = model.predict(np.array(x).reshape(1, n_per_in, n_features))\n",
        "\n",
        "        # Transforming values back to their normal prices\n",
        "        yhat = close_scaler.inverse_transform(yhat)[0]\n",
        "\n",
        "        # DF to store the values and append later, frequency uses business days\n",
        "        pred_df = pd.DataFrame(yhat, \n",
        "                               index=pd.date_range(start=x.index[-1], \n",
        "                                                   periods=len(yhat), \n",
        "                                                   freq=\"B\"),\n",
        "                               columns=[x.columns[0]])\n",
        "\n",
        "        # Updating the predictions DF\n",
        "        predictions.update(pred_df)\n",
        "        \n",
        "    return predictions\n",
        "\n",
        "\n",
        "def val_rmse(df1, df2):\n",
        "    \"\"\"\n",
        "    Calculates the root mean square error between the two Dataframes\n",
        "    \"\"\"\n",
        "    df = df1.copy()\n",
        "    \n",
        "    # Adding a new column with the closing prices from the second DF\n",
        "    df['close2'] = df2.Close\n",
        "    \n",
        "    # Dropping the NaN values\n",
        "    df.dropna(inplace=True)\n",
        "    \n",
        "    # Adding another column containing the difference between the two DFs' closing prices\n",
        "    df['diff'] = df.Close - df.close2\n",
        "    \n",
        "    # Squaring the difference and getting the mean\n",
        "    rms = (df[['diff']]**2).mean()\n",
        "    \n",
        "    # Returning the sqaure root of the root mean square\n",
        "    return float(np.sqrt(rms))\n",
        "  \n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLRJVoHct2yL"
      },
      "source": [
        "# How many periods looking back to learn\n",
        "n_per_in  = 90\n",
        "# How many periods to predict\n",
        "n_per_out = 30\n",
        "# Features \n",
        "n_features = df.shape[1]\n",
        "# Splitting the data into appropriate sequences\n",
        "X, y = split_sequence(df.to_numpy(), n_per_in, n_per_out)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm6yqGZZtm6U",
        "outputId": "d1d31671-e0b1-4504-c823-0908739ba921"
      },
      "source": [
        "## Creating the NN\n",
        "\n",
        "# Instatiating the model\n",
        "model = Sequential()\n",
        "\n",
        "# Activation\n",
        "activ = \"tanh\"\n",
        "\n",
        "# Input layer\n",
        "model.add(LSTM(90, \n",
        "               activation=activ, \n",
        "               return_sequences=True, \n",
        "               input_shape=(n_per_in, n_features)))\n",
        "\n",
        "# Hidden layers\n",
        "layer_maker(n_layers=1, \n",
        "            n_nodes=30, \n",
        "            activation=activ)\n",
        "\n",
        "# Final Hidden layer\n",
        "model.add(LSTM(60, activation=activ))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(n_per_out))\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Compiling the data with selected specifications\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "\n",
        "## Fitting and Training\n",
        "res = model.fit(X, y, epochs=200, batch_size=128, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_33 (LSTM)               (None, 90, 90)            63000     \n",
            "_________________________________________________________________\n",
            "lstm_34 (LSTM)               (None, 90, 30)            14520     \n",
            "_________________________________________________________________\n",
            "lstm_35 (LSTM)               (None, 60)                21840     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 30)                1830      \n",
            "=================================================================\n",
            "Total params: 101,190\n",
            "Trainable params: 101,190\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "45/45 [==============================] - 21s 334ms/step - loss: 0.1792 - accuracy: 0.0252 - val_loss: 0.1509 - val_accuracy: 0.0509\n",
            "Epoch 2/200\n",
            "45/45 [==============================] - 14s 301ms/step - loss: 0.0109 - accuracy: 0.0344 - val_loss: 0.1650 - val_accuracy: 0.0397\n",
            "Epoch 3/200\n",
            "45/45 [==============================] - 14s 301ms/step - loss: 0.0056 - accuracy: 0.0438 - val_loss: 0.1733 - val_accuracy: 0.0620\n",
            "Epoch 4/200\n",
            "45/45 [==============================] - 14s 301ms/step - loss: 0.0039 - accuracy: 0.0653 - val_loss: 0.1806 - val_accuracy: 0.0541\n",
            "Epoch 5/200\n",
            "45/45 [==============================] - 14s 300ms/step - loss: 0.0031 - accuracy: 0.0751 - val_loss: 0.1861 - val_accuracy: 0.0461\n",
            "Epoch 6/200\n",
            "45/45 [==============================] - 13s 300ms/step - loss: 0.0026 - accuracy: 0.0874 - val_loss: 0.1838 - val_accuracy: 0.0541\n",
            "Epoch 7/200\n",
            "45/45 [==============================] - 13s 299ms/step - loss: 0.0023 - accuracy: 0.0925 - val_loss: 0.1941 - val_accuracy: 0.0509\n",
            "Epoch 8/200\n",
            "45/45 [==============================] - 13s 299ms/step - loss: 0.0021 - accuracy: 0.0968 - val_loss: 0.1932 - val_accuracy: 0.0445\n",
            "Epoch 9/200\n",
            "45/45 [==============================] - 13s 298ms/step - loss: 0.0020 - accuracy: 0.1023 - val_loss: 0.1858 - val_accuracy: 0.0588\n",
            "Epoch 10/200\n",
            "30/45 [===================>..........] - ETA: 4s - loss: 0.0018 - accuracy: 0.1150"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV7MXq5ytuAA"
      },
      "source": [
        "visualize_training_results(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUwUzcIwuhbh"
      },
      "source": [
        " #Transforming the actual values to their original price\n",
        "actual = pd.DataFrame(close_scaler.inverse_transform(df[[\"Close\"]]), \n",
        "                      index=df.index, \n",
        "                      columns=[df.columns[0]])\n",
        "\n",
        "# Getting a DF of the predicted values to validate against\n",
        "predictions = validater(n_per_in, n_per_out)\n",
        "\n",
        "# Printing the RMSE\n",
        "print(\"RMSE:\", val_rmse(actual, predictions))\n",
        "    \n",
        "# Plotting\n",
        "plt.figure(figsize=(16,6))\n",
        "\n",
        "# Plotting those predictions\n",
        "plt.plot(predictions, label='Predicted')\n",
        "\n",
        "# Plotting the actual values\n",
        "plt.plot(actual, label='Actual')\n",
        "\n",
        "plt.title(f\"Predicted vs Actual Closing Prices\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "#plt.xlim('2019-05', '2021-05')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct6-dxOzuq21"
      },
      "source": [
        "# Predicting off of the most recent days from the original DF\n",
        "yhat = model.predict(np.array(df.tail(n_per_in)).reshape(1, n_per_in, n_features))\n",
        "\n",
        "# Transforming the predicted values back to their original format\n",
        "yhat = close_scaler.inverse_transform(yhat)[0]\n",
        "\n",
        "# Creating a DF of the predicted prices\n",
        "preds = pd.DataFrame(yhat, \n",
        "                     index=pd.date_range(start=df.index[-1]+timedelta(days=1), \n",
        "                                         periods=len(yhat), \n",
        "                                         freq=\"B\"), \n",
        "                     columns=[df.columns[0]])\n",
        "\n",
        "# Number of periods back to plot the actual values\n",
        "pers = n_per_in\n",
        "\n",
        "# Transforming the actual values to their original price\n",
        "actual = pd.DataFrame(close_scaler.inverse_transform(df[[\"Close\"]].tail(pers)), \n",
        "                      index=df.Close.tail(pers).index, \n",
        "                      columns=[df.columns[0]]).append(preds.head(1))\n",
        "\n",
        "# Printing the predicted prices\n",
        "print(preds)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(16,6))\n",
        "plt.plot(actual, label=\"Actual Prices\")\n",
        "plt.plot(preds, label=\"Predicted Prices\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.xlabel(\"Dates\")\n",
        "plt.title(f\"Forecasting the next {len(yhat)} days\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdeoGRh6vGOX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}